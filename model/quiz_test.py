import cv2
import numpy as np
import mediapipe as mp
import random
import time
from tensorflow.keras.models import load_model
from PIL import ImageFont, ImageDraw, Image  # Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬

# 1. ëª¨ë¸ ë° ì„¤ì • ë¡œë“œ
model_path = "cnn_lstm_sign_language_model_optimized_4.h5"  # ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
model = load_model(model_path)

GESTURES = ['ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…',
            'ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£',
            'ã…', 'ã…’', 'ã…”', 'ã…–', 'ã…¢', 'ã…š', 'ã…Ÿ',
            'ã„²', 'ã„¸', 'ã…ƒ', 'ã…†', 'ã…‰']  # ì œìŠ¤ì²˜ ëª©ë¡

SEQUENCE_LENGTH = 30  # ì‹œí€€ìŠ¤ ê¸¸ì´ (ëª¨ë¸ ì…ë ¥)
IMAGE_SIZE = (64, 64)  # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (ëª¨ë¸ ì…ë ¥)
TIME_LIMIT = 10  # í€´ì¦ˆ ì‹œê°„ ì œí•œ (ì´ˆ)

# MediaPipe ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# í•œê¸€ í°íŠ¸ ì„¤ì • (NanumGothic.ttf ë˜ëŠ” ë‹¤ë¥¸ í•œê¸€ í°íŠ¸ë¥¼ ì‚¬ìš©)
font_path = "/System/Library/Fonts/Supplemental/AppleSDGothicNeo.ttc"  # macOS ê¸°ì¤€
font = ImageFont.truetype(font_path, 32)  # í°íŠ¸ í¬ê¸° ì„¤ì •


# 2. í€´ì¦ˆ ì„¤ì •
def get_new_quiz():
    """ëœë¤ìœ¼ë¡œ ìƒˆë¡œìš´ í€´ì¦ˆ ë¬¸ì œë¥¼ ì„ íƒ"""
    return random.choice(GESTURES), time.time()  # ë¬¸ì œì™€ ì‹œì‘ ì‹œê°„ ë°˜í™˜


current_quiz, start_time = get_new_quiz()  # ì²« ë¬¸ì œ ì„ ì •
sequence = []  # ì‹œí€€ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
feedback_text = ""  # ì‚¬ìš©ì í”¼ë“œë°± ë©”ì‹œì§€ (ë§ì•˜ëŠ”ì§€ ì—¬ë¶€)
feedback_time = 0  # í”¼ë“œë°± ë©”ì‹œì§€ê°€ í‘œì‹œëœ ì‹œê°„

# ì›¹ìº  ì‹¤í–‰
cap = cv2.VideoCapture(0)


def preprocess_landmarks(landmarks):
    """ì† ëœë“œë§ˆí¬ë¥¼ (64x64) ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    frame_image = np.zeros(IMAGE_SIZE, dtype=np.float32)  # ë¹ˆ ì´ë¯¸ì§€ ìƒì„±
    for lm in landmarks:
        px, py = int(lm.x * IMAGE_SIZE[0]), int(lm.y * IMAGE_SIZE[1])
        if 0 <= px < IMAGE_SIZE[0] and 0 <= py < IMAGE_SIZE[1]:
            frame_image[py, px] = 1  # z ê°’ ì—†ì´ ì¢Œí‘œë§Œ ì‚¬ìš©
    return frame_image


with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # í˜„ì¬ ì‹œê°„ í™•ì¸
        elapsed_time = time.time() - start_time
        remaining_time = max(0, TIME_LIMIT - int(elapsed_time))  # ìŒìˆ˜ê°€ ë˜ì§€ ì•Šë„ë¡ ì œí•œ

        predicted_gesture = None  # ë§¤ í”„ë ˆì„ë§ˆë‹¤ ì´ˆê¸°í™”

        # BGR -> RGB ë³€í™˜ ë° MediaPipe ì²˜ë¦¬
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True

        # ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì‹œê°í™”
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                # ëœë“œë§ˆí¬ë¥¼ 64x64 ì´ë¯¸ì§€ë¡œ ë³€í™˜
                frame_image = preprocess_landmarks(hand_landmarks.landmark)
                sequence.append(frame_image)

                # ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ SEQUENCE_LENGTHë¥¼ ì´ˆê³¼í•˜ë©´ ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±°
                if len(sequence) > SEQUENCE_LENGTH:
                    sequence.pop(0)

                # ì‹œí€€ìŠ¤ê°€ ì¶©ë¶„íˆ ìŒ“ì´ë©´ ì˜ˆì¸¡ ìˆ˜í–‰
                if len(sequence) == SEQUENCE_LENGTH:
                    model_input = np.array(sequence)  # ë¦¬ìŠ¤íŠ¸ -> numpy ë°°ì—´ ë³€í™˜
                    model_input = np.expand_dims(model_input, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                    model_input = model_input[..., np.newaxis]  # ì±„ë„ ì¶”ê°€

                    predictions = model.predict(model_input)
                    predicted_gesture_index = np.argmax(predictions)
                    predicted_gesture = GESTURES[predicted_gesture_index]

                    # ì •ë‹µ í™•ì¸
                    if predicted_gesture == current_quiz:
                        feedback_text = " ë§ì•˜ìŠµë‹ˆë‹¤~ ë‹¤ìŒ ë¬¸ì œë¡œ ì´ë™í•©ë‹ˆë‹¤."
                        feedback_time = time.time()  # í”¼ë“œë°± í‘œì‹œ ì‹œì‘ ì‹œê°„
                        current_quiz, start_time = get_new_quiz()  # ìƒˆë¡œìš´ ë¬¸ì œ ì¶œì œ
                        sequence = []  # ì‹œí€€ìŠ¤ ì´ˆê¸°í™”
                    else:
                        feedback_text = " ë” ë…¸ë ¥í•´ë³´ì„¸ìš”!"
                        feedback_time = time.time()

        # ì‹œê°„ ì´ˆê³¼ ì‹œ ìƒˆë¡œìš´ ë¬¸ì œë¡œ ì´ë™
        if elapsed_time > TIME_LIMIT:
            feedback_text = " ì‹œê°„ ì´ˆê³¼! ë‹¤ìŒ ë¬¸ì œë¡œ ì´ë™í•©ë‹ˆë‹¤."
            feedback_time = time.time()
            current_quiz, start_time = get_new_quiz()
            sequence = []  # ì‹œí€€ìŠ¤ ì´ˆê¸°í™”

        # ê²°ê³¼ ì¶œë ¥: OpenCV ì´ë¯¸ì§€ë¥¼ Pillow ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ í•œê¸€ ì¶œë ¥
        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(frame_pil)

        # â³ ë‚¨ì€ ì‹œê°„ ë³„ë„ë¡œ ì¶œë ¥
        draw.text((10, 10), f" ë‚¨ì€ ì‹œê°„: {remaining_time}ì´ˆ", font=font, fill=(0, 255, 255))

        # ğŸ“ í˜„ì¬ ë¬¸ì œ í‘œì‹œ
        draw.text((10, 50), f" ë¬¸ì œ: {current_quiz}", font=font, fill=(255, 255, 255))

        # ğŸ¯ í”¼ë“œë°± ë¬¸êµ¬ ì¶œë ¥ (1ì´ˆ ìœ ì§€)
        if feedback_text and (time.time() - feedback_time <= 1):
            draw.text((10, 100), feedback_text, font=font, fill=(255, 0, 0) if "!" in feedback_text else (0, 255, 0))

        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)

        # í™”ë©´ ì¶œë ¥
        cv2.imshow('Sign Language Quiz', frame)

        if cv2.waitKey(10) & 0xFF == ord('q'):  # q í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
            break

cap.release()
cv2.destroyAllWindows()
